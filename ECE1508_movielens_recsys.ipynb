{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epcdolO1Tlw5"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eithwTf8Tp6-"
      },
      "source": [
        "### Time Aware LOO Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wrote: C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\ratings.csv 1000209\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "RAW = Path(r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\")\n",
        "out_csv = RAW / \"ratings.csv\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    RAW / \"ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    engine=\"python\",\n",
        "    names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
        ")\n",
        "df.to_csv(out_csv, index=False)\n",
        "print(\"wrote:\", out_csv, len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W_pCAnFf4jnu"
      },
      "outputs": [],
      "source": [
        "# Time-aware Leave-One-Out (LOO) split for MovieLens ratings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def _detect_ts_unit(ts_series):\n",
        "    vmax = float(ts_series.max())\n",
        "    return \"ms\" if vmax > 1e12 else \"s\"\n",
        "\n",
        "def time_aware_loo_split(\n",
        "    ratings_csv: str,\n",
        "    out_dir: str,\n",
        "    rating_threshold: float = 3.0,\n",
        "    min_positives: int = 3,\n",
        "    also_csv: bool = False,\n",
        "):\n",
        "    out = Path(out_dir); (out / \"splits\").mkdir(parents=True, exist_ok=True)\n",
        "    ratings = pd.read_csv(ratings_csv)\n",
        "\n",
        "    # 1) Basic checks\n",
        "    need = {\"userId\",\"movieId\",\"rating\",\"timestamp\"}\n",
        "    missing = need - set(ratings.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"ratings.csv missing columns: {missing}\")\n",
        "\n",
        "    # 2) Normalize timestamp and keep implicit positives\n",
        "    unit = _detect_ts_unit(ratings[\"timestamp\"])\n",
        "    ratings[\"ts\"] = pd.to_datetime(ratings[\"timestamp\"], unit=unit)\n",
        "\n",
        "    pos = ratings[ratings[\"rating\"] >= rating_threshold].copy()\n",
        "    # Drop duplicate (user,item) -> keep earliest\n",
        "    pos = pos.sort_values([\"userId\",\"ts\",\"movieId\"], kind=\"mergesort\")\n",
        "    pos = pos.drop_duplicates([\"userId\",\"movieId\"], keep=\"first\")\n",
        "\n",
        "    # Keep users with at least min_positives\n",
        "    pos = pos[pos.groupby(\"userId\")[\"movieId\"].transform(\"size\") >= min_positives].copy()\n",
        "\n",
        "    # 3) Rank by time per user, assign splits: last=test, second last=val (if >=3), rest=train\n",
        "    pos[\"n\"] = pos.groupby(\"userId\")[\"movieId\"].transform(\"size\")\n",
        "    pos[\"idx\"] = pos.groupby(\"userId\").cumcount()\n",
        "    pos[\"split\"] = \"train\"\n",
        "    pos.loc[pos[\"idx\"] == pos[\"n\"]-1, \"split\"] = \"test\"\n",
        "    pos.loc[(pos[\"n\"]>=3) & (pos[\"idx\"] == pos[\"n\"]-2), \"split\"] = \"val\"\n",
        "\n",
        "    train = pos[pos[\"split\"]==\"train\"][[\"userId\",\"movieId\",\"ts\"]].reset_index(drop=True)\n",
        "    val_targets  = pos[pos[\"split\"]==\"val\"][[\"userId\",\"movieId\",\"ts\"]].rename(\n",
        "        columns={\"movieId\":\"val_item\",\"ts\":\"ts_val\"}).reset_index(drop=True)\n",
        "    test_targets = pos[pos[\"split\"]==\"test\"][[\"userId\",\"movieId\",\"ts\"]].rename(\n",
        "        columns={\"movieId\":\"test_item\",\"ts\":\"ts_test\"}).reset_index(drop=True)\n",
        "\n",
        "    # 4) Build ID maps from TRAIN only (contiguous 0..U-1 and 0..I-1)\n",
        "    uids = pd.DataFrame(sorted(train[\"userId\"].unique()), columns=[\"userId\"])\n",
        "    uids[\"uid\"] = range(len(uids))\n",
        "    iids = pd.DataFrame(sorted(train[\"movieId\"].unique()), columns=[\"movieId\"])\n",
        "    iids[\"iid\"] = range(len(iids))\n",
        "\n",
        "    # 5) Also provide indexed versions (useful for MF/ALS)\n",
        "    train_idx = (train.merge(uids, on=\"userId\", how=\"inner\")\n",
        "                      .merge(iids, on=\"movieId\", how=\"inner\"))\n",
        "    val_idx = None\n",
        "    if len(val_targets):\n",
        "        val_idx = (val_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
        "                              .merge(iids, left_on=\"val_item\", right_on=\"movieId\", how=\"left\")\n",
        "                              .drop(columns=[\"movieId\"]))\n",
        "    test_idx = (test_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
        "                               .merge(iids, left_on=\"test_item\", right_on=\"movieId\", how=\"left\")\n",
        "                               .drop(columns=[\"movieId\"]))\n",
        "\n",
        "    # 6) Save outputs\n",
        "    sp = out / \"splits\"\n",
        "    train.to_parquet(sp / \"train.parquet\", index=False)\n",
        "    if len(val_targets):\n",
        "        val_targets.to_parquet(sp / \"val_targets.parquet\", index=False)\n",
        "    test_targets.to_parquet(sp / \"test_targets.parquet\", index=False)\n",
        "    uids.to_parquet(sp / \"user_id_map.parquet\", index=False)\n",
        "    iids.to_parquet(sp / \"item_id_map.parquet\", index=False)\n",
        "    train_idx.to_parquet(sp / \"train_indexed.parquet\", index=False)\n",
        "    if val_idx is not None:\n",
        "        val_idx.to_parquet(sp / \"val_targets_indexed.parquet\", index=False)\n",
        "    test_idx.to_parquet(sp / \"test_targets_indexed.parquet\", index=False)\n",
        "\n",
        "    if also_csv:\n",
        "        train.to_csv(sp / \"train.csv\", index=False)\n",
        "        if len(val_targets): val_targets.to_csv(sp / \"val_targets.csv\", index=False)\n",
        "        test_targets.to_csv(sp / \"test_targets.csv\", index=False)\n",
        "        uids.to_csv(sp / \"user_id_map.csv\", index=False)\n",
        "        iids.to_csv(sp / \"item_id_map.csv\", index=False)\n",
        "        train_idx.to_csv(sp / \"train_indexed.csv\", index=False)\n",
        "        if val_idx is not None:\n",
        "            val_idx.to_csv(sp / \"val_targets_indexed.csv\", index=False)\n",
        "        test_idx.to_csv(sp / \"test_targets_indexed.csv\", index=False)\n",
        "\n",
        "    # 7) Quick stats + cold-start counts\n",
        "    cold_val = int(val_idx[\"iid\"].isna().sum()) if val_idx is not None and \"iid\" in val_idx else 0\n",
        "    cold_test = int(test_idx[\"iid\"].isna().sum()) if \"iid\" in test_idx else 0\n",
        "    stats = f\"\"\"Time-aware LOO split summary\n",
        "Users (TRAIN map): {len(uids)}\n",
        "Items (TRAIN map): {len(iids)}\n",
        "TRAIN positives  : {len(train)}\n",
        "VAL users        : {len(val_targets[\"userId\"].unique()) if len(val_targets) else 0}\n",
        "TEST users       : {len(test_targets[\"userId\"].unique())}\n",
        "Cold-start VAL items  : {cold_val}\n",
        "Cold-start TEST items : {cold_test}\n",
        "\"\"\"\n",
        "    (sp / \"stats.txt\").write_text(stats, encoding=\"utf-8\")\n",
        "    print(stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cap it to only 5 movies per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limited ratings shape: (30200, 4)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load ratings\n",
        "ratings = pd.read_csv(r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\ratings.csv\")\n",
        "\n",
        "# Sort by userId and timestamp (most recent first)\n",
        "ratings = ratings.sort_values([\"userId\", \"timestamp\"], ascending=[True, False])\n",
        "\n",
        "# Keep only the 5 most recent ratings per user\n",
        "ratings_limited = ratings.groupby(\"userId\").head(5).reset_index(drop=True)\n",
        "\n",
        "print(\"Limited ratings shape:\", ratings_limited.shape)\n",
        "\n",
        "# Optionally, save for downstream steps\n",
        "ratings_limited.to_csv(r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\ratings_limited.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThfMPG-5Txll"
      },
      "source": [
        "### Call Time Aware LOO Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boIFiP3OAAgz",
        "outputId": "94890907-82a2-42a9-8279-cff31decd1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time-aware LOO split summary\n",
            "Users (TRAIN map): 5413\n",
            "Items (TRAIN map): 2287\n",
            "TRAIN positives  : 13295\n",
            "VAL users        : 5413\n",
            "TEST users       : 5413\n",
            "Cold-start VAL items  : 306\n",
            "Cold-start TEST items : 343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "time_aware_loo_split(\n",
        "    ratings_csv=r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\ratings_limited.csv\",\n",
        "    out_dir=r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\",\n",
        "    rating_threshold=3.0,   # implicit “like” threshold\n",
        "    min_positives=3,        # drop users with <3 positives\n",
        "    also_csv=True           # optional CSV mirrors\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-rj0cuAT4t8"
      },
      "source": [
        "# Load splits + quick helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s6-kBI8_T9Gw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "users: 5413 items: 2287 train rows: 13295\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "SPLITS = Path(r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\splits\")\n",
        "\n",
        "train = pd.read_parquet(SPLITS / \"train_indexed.parquet\")         # [uid, iid, ts]\n",
        "val_idx = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\") # [userId, uid, val_item, iid, ts_val]\n",
        "test_idx = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")  # [userId, uid, test_item, iid, ts_test]\n",
        "\n",
        "# sizes\n",
        "U = int(train[\"uid\"].max()) + 1\n",
        "I = int(train[\"iid\"].max()) + 1\n",
        "print(\"users:\", U, \"items:\", I, \"train rows:\", len(train))\n",
        "\n",
        "# users×items implicit matrix (Windows-friendly dtypes)\n",
        "rows = train[\"uid\"].to_numpy(dtype=np.int32, copy=False)\n",
        "cols = train[\"iid\"].to_numpy(dtype=np.int32, copy=False)\n",
        "data = np.ones(len(train), dtype=np.float32)\n",
        "\n",
        "R = csr_matrix((data, (rows, cols)), shape=(U, I), dtype=np.float32)\n",
        "\n",
        "# fast lookup: items seen in TRAIN per user\n",
        "user_seen = train.groupby(\"uid\")[\"iid\"].apply(set).to_dict()\n",
        "\n",
        "# evaluation helper\n",
        "def candidate_coverage(cand_df, targets_df, tgt_col=\"iid\"):\n",
        "    df = cand_df.merge(targets_df[[\"uid\", tgt_col]], on=\"uid\", how=\"inner\")\n",
        "    df = df[df[tgt_col].notna()]  # drop cold-start items\n",
        "    return np.mean([int(t) in set(c) for t, c in zip(df[tgt_col], df[\"candidates\"])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMpEQftzUDUk"
      },
      "source": [
        "# Artifact A: Popularity (train-only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8691IfAeUFjl"
      },
      "outputs": [],
      "source": [
        "# TRAIN-only popularity\n",
        "pop = (\n",
        "    train.groupby(\"iid\").size()\n",
        "         .sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "def top_pop_unseen(u_seen, P=50):\n",
        "    out = []\n",
        "    for iid in pop.index:\n",
        "        if iid not in u_seen:\n",
        "            out.append(int(iid))\n",
        "            if len(out) >= P:\n",
        "                break\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Artifact B: item-item (w sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn item–item fitted on (2287, 5413)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# item × user matrix\n",
        "item_users = R.T.tocsr()\n",
        "item_users.sort_indices()\n",
        "\n",
        "knn = NearestNeighbors(\n",
        "    n_neighbors=51,      # 50 real neighbors\n",
        "    metric=\"cosine\",\n",
        "    algorithm=\"brute\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "knn.fit(item_users)\n",
        "print(\"sklearn item–item fitted on\", item_users.shape)\n",
        "\n",
        "def item_neighbors_from_history_sklearn(u_seen, per_item=20):\n",
        "    C = []\n",
        "    for iid in u_seen:\n",
        "        dists, idxs = knn.kneighbors(item_users[iid], n_neighbors=per_item+1, return_distance=True)\n",
        "        neigh_ids = idxs[0][1:]   # drop self\n",
        "        C.extend(int(j) for j in neigh_ids)\n",
        "    return C\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Artifact C: ALS Train only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
            "  check_blas_config()\n",
            "100%|██████████| 10/10 [00:00<00:00, 57.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALS trained.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from implicit.als import AlternatingLeastSquares\n",
        "\n",
        "# ALS model (we can tune later)\n",
        "als = AlternatingLeastSquares(\n",
        "    factors=64,\n",
        "    regularization=0.05,\n",
        "    iterations=10,\n",
        "    use_gpu=False\n",
        ")\n",
        "\n",
        "# implicit ALS wants item×user\n",
        "als.fit(R.T.tocsr())\n",
        "\n",
        "print(\"ALS trained.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvHl_Km_UQKa"
      },
      "source": [
        "# Build candidate pools (w artifacts - popularity/item-item,als)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrjASCypURPL",
        "outputId": "95900d54-9472-4c23-a416-bc5ae087221f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5413/5413 [10:49<00:00,  8.34it/s]\n",
            "100%|██████████| 5413/5413 [11:14<00:00,  8.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote candidates to: C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\candidates\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pyarrow as pa, pyarrow.parquet as pq\n",
        "\n",
        "def mf_top_unseen(uid: int, Rk):\n",
        "    # ALS recommend already filters liked items\n",
        "    ids, scores = als.recommend(\n",
        "        userid=int(uid),\n",
        "        user_items=R[int(uid)],\n",
        "        N=Rk,\n",
        "        filter_already_liked_items=True,\n",
        "        recalculate_user=True,\n",
        "    )\n",
        "    return [int(i) for i in ids]\n",
        "\n",
        "def build_pool_for_user(uid: int,\n",
        "                        P=200,        # how many pop to try\n",
        "                        K=400,       # final cap\n",
        "                        Rk=200,       # how many ALS recs to try\n",
        "                        knn_per_item=20):  # how many neighbors per seen item\n",
        "    seen = user_seen.get(uid, set())\n",
        "    seen_set = set(seen)\n",
        "\n",
        "    C = []\n",
        "\n",
        "    # 1) popularity (train-only)\n",
        "    C += top_pop_unseen(seen, P=P)\n",
        "\n",
        "    # 2) ALS / MF (only if user is warm)\n",
        "    if len(seen):\n",
        "        C += mf_top_unseen(uid, Rk=Rk)\n",
        "\n",
        "    # 3) item–item (sklearn) — only if user has history\n",
        "    if len(seen):\n",
        "        few = list(seen)[:12]          # only 5 items from history\n",
        "        C += item_neighbors_from_history_sklearn(few, per_item=knn_per_item)\n",
        "\n",
        "    # 4) de-dup + drop seen + cap\n",
        "    dedup = []\n",
        "    for iid in C:\n",
        "        if iid in seen_set:\n",
        "            continue\n",
        "        if iid in dedup:\n",
        "            continue\n",
        "        dedup.append(iid)\n",
        "        if len(dedup) >= K:\n",
        "            break\n",
        "\n",
        "    return dedup\n",
        "\n",
        "\n",
        "def make_candidates(user_ids, P=200, K=400, Rk=200, knn_per_item=20):\n",
        "    rows = []\n",
        "    for u in tqdm(user_ids):\n",
        "        rows.append({\n",
        "            \"uid\": int(u),\n",
        "            \"candidates\": build_pool_for_user(\n",
        "                int(u),\n",
        "                P=P,\n",
        "                K=K,\n",
        "                Rk=Rk,\n",
        "                knn_per_item=knn_per_item,\n",
        "            )\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# who to build for\n",
        "users_val  = sorted(val_idx[\"uid\"].unique())  if len(val_idx)  else []\n",
        "users_test = sorted(test_idx[\"uid\"].unique()) if len(test_idx) else []\n",
        "\n",
        "# build pools\n",
        "cand_val  = make_candidates(users_val,  P=20,  K=50, Rk=20, knn_per_item=10)\n",
        "cand_test = make_candidates(users_test, P=20,  K=50, Rk=20, knn_per_item=10)\n",
        "\n",
        "# save\n",
        "OUT = SPLITS.parent / \"candidates\"\n",
        "OUT.mkdir(exist_ok=True)\n",
        "cand_val.to_parquet(OUT / \"val.parquet\", index=False)\n",
        "cand_test.to_parquet(OUT / \"test.parquet\", index=False)\n",
        "print(\"Wrote candidates to:\", OUT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl5crxFsUUBz"
      },
      "source": [
        "# Check candidate coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3qjvAGrUWOB",
        "outputId": "02cfb227-21a4-4345-fbd4-af4f45f3ef21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate coverage  val=10.48%  test=9.53%\n"
          ]
        }
      ],
      "source": [
        "val_cov  = candidate_coverage(cand_val,  val_idx,  \"iid\") if len(cand_val)  else float(\"nan\")\n",
        "test_cov = candidate_coverage(cand_test, test_idx, \"iid\") if len(cand_test) else float(\"nan\")\n",
        "print(f\"Candidate coverage  val={val_cov:.2%}  test={test_cov:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load & Define Covered Users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_item: dropped 306 rows (cold-start/invalid); kept 5107\n",
            "test_item: dropped 343 rows (cold-start/invalid); kept 5070\n",
            "Coverage  val=10.48%  test=9.53%\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ROOT = Path(\"C:/Users/abdul/ece1508gp/movielens_dataset\")\n",
        "SPLITS = ROOT / \"splits\"\n",
        "CANDS  = ROOT / \"candidates\"\n",
        "\n",
        "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")   # [uid,iid,ts]\n",
        "val_idx   = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\")\n",
        "test_idx  = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")\n",
        "\n",
        "cand_val  = pd.read_parquet(CANDS / \"val.parquet\")   # [uid, candidates(list[iid])]\n",
        "cand_test = pd.read_parquet(CANDS / \"test.parquet\")\n",
        "\n",
        "def coverage_rows(cands_df, targets_df, tgt_name):\n",
        "    # merge candidates with target iid (indexed) for the same uid\n",
        "    df = cands_df.merge(\n",
        "        targets_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": tgt_name}),\n",
        "        on=\"uid\", how=\"inner\"\n",
        "    )\n",
        "\n",
        "    # drop cold-start targets (iid is NaN) and rows without candidates\n",
        "    before = len(df)\n",
        "    df = df[df[tgt_name].notna() & df[\"candidates\"].notna()].copy()\n",
        "    dropped = before - len(df)\n",
        "\n",
        "    # ensure candidates are lists\n",
        "    df[\"candidates\"] = df[\"candidates\"].apply(lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray)) else [])\n",
        "\n",
        "    # use pandas nullable Int64 to avoid int(NaN) issues\n",
        "    df[tgt_name] = df[tgt_name].astype(\"Int64\")\n",
        "\n",
        "    # membership test (no int(...) cast needed now)\n",
        "    df[\"target_in_pool\"] = [t in set(c) for t, c in zip(df[tgt_name], df[\"candidates\"])]\n",
        "\n",
        "    print(f\"{tgt_name}: dropped {dropped} rows (cold-start/invalid); kept {len(df)}\")\n",
        "    return df\n",
        "\n",
        "val_cov  = coverage_rows(cand_val,  val_idx,  \"val_item\")\n",
        "test_cov = coverage_rows(cand_test, test_idx, \"test_item\")\n",
        "\n",
        "val_covered  = val_cov[val_cov[\"target_in_pool\"]].copy()\n",
        "test_covered = test_cov[test_cov[\"target_in_pool\"]].copy()\n",
        "\n",
        "print(f\"Coverage  val={len(val_covered)/len(val_cov):.2%}  test={len(test_covered)/len(test_cov):.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get Covered Users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Users valid for eval  val=535  test=483\n"
          ]
        }
      ],
      "source": [
        "def mark_coverage(cands_df: pd.DataFrame, targets_df: pd.DataFrame, tgt_name: str):\n",
        "    df = cands_df.merge(\n",
        "        targets_df[[\"uid\",\"iid\"]].rename(columns={\"iid\": tgt_name}),\n",
        "        on=\"uid\", how=\"inner\"\n",
        "    )\n",
        "    # guard against NaNs and non-lists\n",
        "    df[\"candidates\"] = df[\"candidates\"].apply(\n",
        "        lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray, pd.Series)) else []\n",
        "    )\n",
        "    # fill NaNs to avoid int() on NaN\n",
        "    tgt = df[tgt_name].fillna(-1).astype(int).to_numpy()\n",
        "    df[\"target_in_pool\"] = [int(t) in set(c) for t, c in zip(tgt, df[\"candidates\"])]\n",
        "    return df[[\"uid\",\"target_in_pool\"]]\n",
        "\n",
        "val_mark  = mark_coverage(cand_val,  val_idx,  \"val_item\")\n",
        "test_mark = mark_coverage(cand_test, test_idx, \"test_item\")\n",
        "\n",
        "covered_val_uids  = set(val_mark.loc[val_mark[\"target_in_pool\"], \"uid\"])\n",
        "covered_test_uids = set(test_mark.loc[test_mark[\"target_in_pool\"], \"uid\"])\n",
        "\n",
        "print(f\"Users valid for eval  val={len(covered_val_uids)}  test={len(covered_test_uids)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sanity check coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval coverage val=100.00% test=100.00%\n"
          ]
        }
      ],
      "source": [
        "# Restrict targets and pools to the covered users only (these will have 100% coverage by construction)\n",
        "val_eval_targets  = val_idx[val_idx[\"uid\"].isin(covered_val_uids)].copy()\n",
        "test_eval_targets = test_idx[test_idx[\"uid\"].isin(covered_test_uids)].copy()\n",
        "\n",
        "cand_val_eval  = cand_val[cand_val[\"uid\"].isin(covered_val_uids)].reset_index(drop=True)\n",
        "cand_test_eval = cand_test[cand_test[\"uid\"].isin(covered_test_uids)].reset_index(drop=True)\n",
        "\n",
        "# (Optional) sanity check – should print 100%/100%\n",
        "def coverage_percent(cands_df, targets_df, tgt_col):\n",
        "    df = cands_df.merge(targets_df[[\"uid\", tgt_col]], on=\"uid\")\n",
        "    return np.mean([int(t) in set(c) for t, c in zip(df[tgt_col], df[\"candidates\"])])\n",
        "\n",
        "print(\"Eval coverage\",\n",
        "      f\"val={coverage_percent(cand_val_eval,  val_eval_targets,  'iid'):.2%}\",\n",
        "      f\"test={coverage_percent(cand_test_eval, test_eval_targets, 'iid'):.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train ALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0 seconds\n",
            "  warnings.warn(\n",
            "100%|██████████| 200/200 [00:04<00:00, 42.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALS shapes  user_factors: (5413, 96)  item_factors: (2287, 96)  U: 5413  I: 2287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.nearest_neighbours import bm25_weight, tfidf_weight \n",
        "\n",
        "# Build users × items CSR from train_idx \n",
        "U = int(train_idx[\"uid\"].max()) + 1\n",
        "I = int(train_idx[\"iid\"].max()) + 1\n",
        "\n",
        "rows = train_idx[\"uid\"].to_numpy(dtype=np.int32, copy=False)\n",
        "cols = train_idx[\"iid\"].to_numpy(dtype=np.int32, copy=False)\n",
        "data = np.ones(len(train_idx), dtype=np.float32)\n",
        "\n",
        "alpha = 15\n",
        "R = csr_matrix((data, (rows, cols)), shape=(U, I), dtype=np.float32)\n",
        "X = bm25_weight(R, K1=100, B=0.8).astype(np.float32)\n",
        "\n",
        "# Train ALS on users × items (keeps names aligned) \n",
        "als = AlternatingLeastSquares(\n",
        "    factors=96,\n",
        "    regularization=0.05,\n",
        "    iterations=200,\n",
        "    use_gpu=False,     \n",
        "    dtype=np.float32,\n",
        ")\n",
        "als.fit(alpha*X)\n",
        "\n",
        "# Cache factors with consistent shapes\n",
        "U_f = als.user_factors   # shape [U, F]  user embeddings\n",
        "V_f = als.item_factors   # shape [I, F]  item embeddings\n",
        "\n",
        "print(\"ALS shapes  user_factors:\", U_f.shape, \" item_factors:\", V_f.shape, \" U:\", U, \" I:\", I)\n",
        "assert U_f.shape[0] == U and V_f.shape[0] == I\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL]  ALS HR@10=0.290  NDCG@10=0.149\n",
            "[TEST] ALS HR@10=0.180  NDCG@10=0.097\n"
          ]
        }
      ],
      "source": [
        "# 0) Join pools with their (covered) targets -> one tidy frame per split\n",
        "val_eval  = (cand_val_eval\n",
        "             .merge(val_eval_targets[[\"uid\",\"iid\"]]\n",
        "                    .rename(columns={\"iid\":\"target\"}), on=\"uid\"))\n",
        "test_eval = (cand_test_eval\n",
        "             .merge(test_eval_targets[[\"uid\",\"iid\"]]\n",
        "                    .rename(columns={\"iid\":\"target\"}), on=\"uid\"))\n",
        "\n",
        "# 1) Cache ALS factors\n",
        "U_f = als.user_factors            # [U, F]\n",
        "V_f = als.item_factors            # [I, F]\n",
        "I   = V_f.shape[0]\n",
        "\n",
        "def score_als(uid: int, cand_iids: list[int]) -> np.ndarray:\n",
        "    \"\"\"Return ALS scores for the candidate items of a user.\"\"\"\n",
        "    if not cand_iids:\n",
        "        return np.asarray([])\n",
        "    u = U_f[int(uid)]\n",
        "    # keep only in-bounds item ids (defensive)\n",
        "    c = np.array([int(i) for i in cand_iids if 0 <= int(i) < I], dtype=np.int64)\n",
        "    if c.size == 0:\n",
        "        return np.asarray([])\n",
        "    return V_f[c] @ u\n",
        "\n",
        "def hit_at_k(ranked, tgt, k=10):\n",
        "    return 1.0 if tgt in ranked[:k] else 0.0\n",
        "\n",
        "def ndcg_at_k(ranked, tgt, k=10):\n",
        "    for rank, iid in enumerate(ranked[:k], start=1):\n",
        "        if iid == tgt:\n",
        "            return 1.0 / np.log2(rank + 1)  # +1 in denom because ranks start at 1\n",
        "    return 0.0\n",
        "\n",
        "def eval_pool(df_eval: pd.DataFrame, scorer, k=10):\n",
        "    \"\"\"df_eval must have columns: uid, candidates (list[int]), target (int).\"\"\"\n",
        "    hits, ndcgs = [], []\n",
        "    for _, r in df_eval.iterrows():\n",
        "        uid  = int(r[\"uid\"])\n",
        "        cnds = [int(x) for x in (r[\"candidates\"] if isinstance(r[\"candidates\"], (list, tuple, np.ndarray, pd.Series)) else [])]\n",
        "        tgt  = int(r[\"target\"])\n",
        "        if not cnds:\n",
        "            continue\n",
        "        scores = scorer(uid, cnds)\n",
        "        if scores.size == 0:\n",
        "            continue\n",
        "        order  = np.argsort(-scores)\n",
        "        ranked = [cnds[i] for i in order]\n",
        "        hits.append(hit_at_k(ranked, tgt, k))\n",
        "        ndcgs.append(ndcg_at_k(ranked, tgt, k))\n",
        "    return float(np.mean(hits)), float(np.mean(ndcgs))\n",
        "\n",
        "# VAL (use for tuning)\n",
        "hr_v, ndcg_v = eval_pool(val_eval, score_als, k=10)\n",
        "print(f\"[VAL]  ALS HR@10={hr_v:.3f}  NDCG@10={ndcg_v:.3f}\")\n",
        "\n",
        "# TEST (final report)\n",
        "hr_t, ndcg_t = eval_pool(test_eval, score_als, k=10)\n",
        "print(f\"[TEST] ALS HR@10={hr_t:.3f}  NDCG@10={ndcg_t:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[VAL]  P@10=0.0290  R@10=0.2897  F1@10=0.0527\n",
            "[TEST] P@10=0.0180  R@10=0.1801  F1@10=0.0327\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def eval_precision_recall_f1(df_eval: pd.DataFrame, scorer, k=10):\n",
        "    \"\"\"df_eval: columns [uid, candidates(list[int]), target(int)]\"\"\"\n",
        "    precisions, recalls, f1s = [], [], []\n",
        "    for _, r in df_eval.iterrows():\n",
        "        uid  = int(r[\"uid\"])\n",
        "        cnds = r[\"candidates\"]\n",
        "        if not isinstance(cnds, (list, tuple, np.ndarray, pd.Series)) or len(cnds) == 0:\n",
        "            continue\n",
        "        cnds = [int(x) for x in cnds]\n",
        "\n",
        "        scores = scorer(uid, cnds)\n",
        "        if scores.size == 0:\n",
        "            continue\n",
        "\n",
        "        # get top-k efficiently and sort them\n",
        "        k_eff = min(k, scores.size)\n",
        "        topk_idx = np.argpartition(-scores, k_eff-1)[:k_eff]\n",
        "        topk_idx = topk_idx[np.argsort(-scores[topk_idx])]\n",
        "        topk_items = [cnds[i] for i in topk_idx]\n",
        "\n",
        "        hit = int(int(r[\"target\"]) in topk_items)\n",
        "        prec = hit / k                  # k is fixed per-user\n",
        "        rec  = float(hit)               # 1 relevant item in LOO\n",
        "        f1   = (2*prec*rec)/(prec+rec) if hit else 0.0\n",
        "\n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return float(np.mean(precisions)), float(np.mean(recalls)), float(np.mean(f1s))\n",
        "\n",
        "# Example usage with your ALS scorer:\n",
        "p_v, r_v, f1_v = eval_precision_recall_f1(val_eval,  score_als, k=10)\n",
        "p_t, r_t, f1_t = eval_precision_recall_f1(test_eval, score_als, k=10)\n",
        "print(f\"[VAL]  P@10={p_v:.4f}  R@10={r_v:.4f}  F1@10={f1_v:.4f}\")\n",
        "print(f\"[TEST] P@10={p_t:.4f}  R@10={r_t:.4f}  F1@10={f1_t:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0 seconds\n",
            "  warnings.warn(\n",
            "100%|██████████| 150/150 [00:03<00:00, 38.17it/s]\n",
            "100%|██████████| 150/150 [00:04<00:00, 36.51it/s]\n",
            "100%|██████████| 150/150 [00:03<00:00, 40.10it/s]\n",
            "100%|██████████| 200/200 [00:04<00:00, 40.92it/s]\n",
            "100%|██████████| 200/200 [00:04<00:00, 40.55it/s]\n",
            "100%|██████████| 200/200 [00:05<00:00, 35.91it/s]\n",
            "100%|██████████| 200/200 [00:07<00:00, 25.71it/s]\n",
            "100%|██████████| 200/200 [00:06<00:00, 32.96it/s]\n",
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0005388259887695312 seconds\n",
            "  warnings.warn(\n",
            "100%|██████████| 200/200 [00:06<00:00, 32.39it/s]\n",
            "100%|██████████| 200/200 [00:05<00:00, 35.54it/s]\n",
            "100%|██████████| 200/200 [00:06<00:00, 33.07it/s]\n",
            "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0011246204376220703 seconds\n",
            "  warnings.warn(\n",
            "100%|██████████| 200/200 [00:05<00:00, 36.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   factors   reg  alpha  iters    val_HR  val_NDCG     val_P     val_R  \\\n",
            "0       64  0.05     15    150  0.324611  0.171206  0.032461  0.324611   \n",
            "1       96  0.05     15    200  0.290966  0.149671  0.029097  0.290966   \n",
            "2      128  0.10     10    200  0.256698  0.126655  0.025670  0.256698   \n",
            "3      128  0.05     20    200  0.256698  0.126034  0.025670  0.256698   \n",
            "\n",
            "     val_F1   test_HR  test_NDCG    test_P    test_R   test_F1  \n",
            "0  0.059020  0.220152   0.113792  0.022015  0.220152  0.040028  \n",
            "1  0.052903  0.189786   0.099426  0.018979  0.189786  0.034507  \n",
            "2  0.046672  0.166322   0.085808  0.016632  0.166322  0.030240  \n",
            "3  0.046672  0.167702   0.087037  0.016770  0.167702  0.030491  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.nearest_neighbours import bm25_weight\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Helper metric functions\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def hit_at_k(ranked, tgt, k=10):\n",
        "    return 1.0 if tgt in ranked[:k] else 0.0\n",
        "\n",
        "def ndcg_at_k(ranked, tgt, k=10):\n",
        "    for rank, iid in enumerate(ranked[:k], start=1):\n",
        "        if iid == tgt:\n",
        "            return 1.0 / np.log2(rank + 1)\n",
        "    return 0.0\n",
        "\n",
        "def precision_recall_f1(ranked, tgt, k=10):\n",
        "    hit = int(tgt in ranked[:k])\n",
        "    prec = hit / k\n",
        "    rec = float(hit)         # because only 1 relevant item in LOO\n",
        "    f1 = (2*prec*rec)/(prec+rec) if hit else 0.0\n",
        "    return prec, rec, f1\n",
        "\n",
        "def eval_pool(df_eval, scorer, k=10):\n",
        "    hits, ndcgs, precs, recs, f1s = [], [], [], [], []\n",
        "    for _, r in df_eval.iterrows():\n",
        "        uid  = int(r[\"uid\"])\n",
        "        cnds = r[\"candidates\"]\n",
        "        if not isinstance(cnds, (list, tuple, np.ndarray, pd.Series)) or len(cnds) == 0:\n",
        "            continue\n",
        "        cnds = [int(x) for x in cnds]\n",
        "        scores = scorer(uid, cnds)\n",
        "        if scores.size == 0:\n",
        "            continue\n",
        "        order  = np.argsort(-scores)\n",
        "        ranked = [cnds[i] for i in order]\n",
        "        hits.append(hit_at_k(ranked, int(r[\"target\"]), k))\n",
        "        ndcgs.append(ndcg_at_k(ranked, int(r[\"target\"]), k))\n",
        "        p, r_, f1 = precision_recall_f1(ranked, int(r[\"target\"]), k)\n",
        "        precs.append(p); recs.append(r_); f1s.append(f1)\n",
        "    return (\n",
        "        float(np.mean(hits)), float(np.mean(ndcgs)),\n",
        "        float(np.mean(precs)), float(np.mean(recs)), float(np.mean(f1s))\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Training + evaluation function\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def train_eval_als_once(seed, R, alpha, factors, reg, iters, use_gpu,\n",
        "                        val_eval, test_eval, k=10):\n",
        "    X = bm25_weight(R, K1=100, B=0.8).astype(np.float32)\n",
        "    als = AlternatingLeastSquares(\n",
        "        factors=factors,\n",
        "        regularization=reg,\n",
        "        iterations=iters,\n",
        "        use_gpu=use_gpu,\n",
        "        dtype=np.float32,\n",
        "        random_state=seed,\n",
        "    )\n",
        "    als.fit(alpha * X)\n",
        "\n",
        "    U_f = als.user_factors\n",
        "    V_f = als.item_factors\n",
        "    I   = V_f.shape[0]\n",
        "\n",
        "    def score_als(uid, cand_iids):\n",
        "        if not cand_iids: return np.asarray([])\n",
        "        u = U_f[int(uid)]\n",
        "        c = np.array([int(i) for i in cand_iids if 0 <= int(i) < I], dtype=np.int64)\n",
        "        if c.size == 0: return np.asarray([])\n",
        "        return V_f[c] @ u\n",
        "\n",
        "    return eval_pool(val_eval,  score_als, k), eval_pool(test_eval, score_als, k)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Grid search over hyperparameters\n",
        "# ------------------------------------------------------\n",
        "\n",
        "param_grid = [\n",
        "    {\"factors\": 64,  \"reg\": 0.05, \"alpha\": 15, \"iters\": 150},\n",
        "    {\"factors\": 96,  \"reg\": 0.05, \"alpha\": 15, \"iters\": 200},\n",
        "    {\"factors\": 128, \"reg\": 0.1,  \"alpha\": 10, \"iters\": 200},\n",
        "    {\"factors\": 128, \"reg\": 0.05, \"alpha\": 20, \"iters\": 200},\n",
        "]\n",
        "\n",
        "results = []\n",
        "seeds = [0, 1, 2]  # average across a few random seeds\n",
        "\n",
        "for params in param_grid:\n",
        "    vals, tests = [], []\n",
        "    for s in seeds:\n",
        "        val_metrics, test_metrics = train_eval_als_once(\n",
        "            seed=s,\n",
        "            R=R,\n",
        "            alpha=params[\"alpha\"],\n",
        "            factors=params[\"factors\"],\n",
        "            reg=params[\"reg\"],\n",
        "            iters=params[\"iters\"],\n",
        "            use_gpu=False,\n",
        "            val_eval=val_eval,\n",
        "            test_eval=test_eval,\n",
        "            k=10,\n",
        "        )\n",
        "        vals.append(val_metrics)\n",
        "        tests.append(test_metrics)\n",
        "\n",
        "    vals, tests = np.array(vals), np.array(tests)\n",
        "    val_mean, val_std = vals.mean(0), vals.std(0)\n",
        "    test_mean, test_std = tests.mean(0), tests.std(0)\n",
        "\n",
        "    results.append({\n",
        "        **params,\n",
        "        \"val_HR\": val_mean[0], \"val_NDCG\": val_mean[1],\n",
        "        \"val_P\": val_mean[2],  \"val_R\": val_mean[3],  \"val_F1\": val_mean[4],\n",
        "        \"test_HR\": test_mean[0], \"test_NDCG\": test_mean[1],\n",
        "        \"test_P\": test_mean[2],  \"test_R\": test_mean[3], \"test_F1\": test_mean[4],\n",
        "    })\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Results summary\n",
        "# ------------------------------------------------------\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "print(res_df.sort_values(\"val_NDCG\", ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best ALS hyperparameters: factors=64, regularization=0.05, alpha=15, iterations=150"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMhHE0NBlH/BSXrGjJvquND",
      "include_colab_link": true,
      "mount_file_id": "1v14zduS8ZnCfMpMoMMIvkrRdQZqD7Ei0",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ece1508gp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
