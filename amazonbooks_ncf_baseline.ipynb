{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:08:29.580049Z",
     "start_time": "2025-11-18T02:08:20.615222Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Base project directory\n",
    "BASE = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "\n",
    "SPLITS = BASE / \"splits\"\n",
    "CANDS = BASE / \"candidates\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:08:31.093385Z",
     "start_time": "2025-11-18T02:08:29.626799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")\n",
    "val_tgt = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\")\n",
    "test_tgt = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")\n",
    "\n",
    "cand_val = pd.read_parquet(CANDS / \"val.parquet\")\n",
    "cand_test = pd.read_parquet(CANDS / \"test.parquet\")\n",
    "\n",
    "print(\"Train rows:\", len(train_idx))\n",
    "print(\"Val users:\", len(val_tgt[\"uid\"].unique()))\n",
    "print(\"Test users:\", len(test_tgt[\"uid\"].unique()))\n",
    "\n",
    "# Determine number of users & items\n",
    "num_users = int(train_idx[\"uid\"].max()) + 1\n",
    "num_items = int(train_idx[\"iid\"].max()) + 1\n",
    "\n",
    "print(\"num_users =\", num_users)\n",
    "print(\"num_items =\", num_items)"
   ],
   "id": "76a358fbf63296fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 697181\n",
      "Val users: 64301\n",
      "Test users: 63492\n",
      "num_users = 64541\n",
      "num_items = 26531\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:08:31.112485Z",
     "start_time": "2025-11-18T02:08:31.104296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NCFDataset(Dataset):\n",
    "\n",
    "    # For each positive (u,i), sample num_neg negative items j.\n",
    "\n",
    "    def __init__(self, df, num_items, num_neg=4):\n",
    "        self.users = df[\"uid\"].values.astype(np.int64)\n",
    "        self.items = df[\"iid\"].values.astype(np.int64)\n",
    "        self.num_items = num_items\n",
    "        self.num_neg = num_neg\n",
    "\n",
    "        # Build user->positive set to avoid sampling positives\n",
    "        user_pos = {}\n",
    "        for u, i in zip(self.users, self.items):\n",
    "            user_pos.setdefault(u, set()).add(i)\n",
    "        self.user_pos = user_pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u = self.users[idx]\n",
    "        i = self.items[idx]\n",
    "\n",
    "        # Positive sample\n",
    "        user_list = [u]\n",
    "        item_list = [i]\n",
    "        label_list = [1.0]\n",
    "\n",
    "        # Negative samples\n",
    "        pos_items = self.user_pos[u]\n",
    "        for _ in range(self.num_neg):\n",
    "            j = np.random.randint(0, self.num_items)\n",
    "            while j in pos_items:\n",
    "                j = np.random.randint(0, self.num_items)\n",
    "            user_list.append(u)\n",
    "            item_list.append(j)\n",
    "            label_list.append(0.0)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(user_list, dtype=torch.long),\n",
    "            torch.tensor(item_list, dtype=torch.long),\n",
    "            torch.tensor(label_list, dtype=torch.float32),\n",
    "        )"
   ],
   "id": "e4c52784d810b242",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:08:31.134742Z",
     "start_time": "2025-11-18T02:08:31.128980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NCF(nn.Module):\n",
    "\n",
    "    def __init__(self, num_users, num_items, emb_dim=64, mlp_dims=(128, 64, 32)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = emb_dim * 2\n",
    "        for h in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.out = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        v = self.item_emb(item)\n",
    "        x = torch.cat([u, v], dim=-1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.squeeze(-1)"
   ],
   "id": "93a3e340a3142cff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:14:57.437526Z",
     "start_time": "2025-11-18T02:08:31.145406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 5\n",
    "NEG_PER_POS = 4\n",
    "LR = 1e-3\n",
    "\n",
    "train_ds = NCFDataset(train_idx, num_items=num_items, num_neg=NEG_PER_POS)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "model = NCF(num_users, num_items).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for users, items, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        users = users.view(-1).to(device)\n",
    "        items = items.view(-1).to(device)\n",
    "        labels = labels.view(-1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(users, items)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} - loss: {total_loss / len(train_loader):.4f}\")"
   ],
   "id": "36bfcdd61c91c358",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1362/1362 [01:19<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1362/1362 [01:16<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss: 0.3355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1362/1362 [01:13<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss: 0.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1362/1362 [01:17<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss: 0.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1362/1362 [01:16<00:00, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss: 0.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:14:57.481634Z",
     "start_time": "2025-11-18T02:14:57.473865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_split(model, cand_df, tgt_df, topk=10, max_users=None):\n",
    "\n",
    "    # Evaluate NCF on val/test split using the candidate pools.\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tgt = tgt_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": \"target_iid\"})\n",
    "    df = cand_df.merge(tgt, on=\"uid\", how=\"inner\")\n",
    "\n",
    "    if max_users is not None:\n",
    "        df = df.iloc[:max_users]\n",
    "\n",
    "    hits, ndcgs, precs = [], [], []\n",
    "    skipped = 0\n",
    "\n",
    "    for row in tqdm(df.itertuples(), total=len(df), desc=\"Eval users\"):\n",
    "        uid = int(row.uid)\n",
    "        cands = list(row.candidates)\n",
    "        target = int(row.target_iid)\n",
    "\n",
    "        # skip if target not in candidate pool\n",
    "        if target not in cands:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        items = torch.tensor(cands, device=device)\n",
    "        users = torch.full_like(items, uid)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = model(users, items).cpu().numpy()\n",
    "\n",
    "        ranking_idx = np.argsort(-scores)\n",
    "        topk_items = [cands[i] for i in ranking_idx[:topk]]\n",
    "\n",
    "        hit = int(target in topk_items)\n",
    "        hits.append(hit)\n",
    "\n",
    "        if hit:\n",
    "            rank = topk_items.index(target) + 1\n",
    "            ndcgs.append(1 / np.log2(rank + 1))\n",
    "        else:\n",
    "            ndcgs.append(0)\n",
    "\n",
    "        precs.append(hit / topk)\n",
    "\n",
    "    hr = float(np.mean(hits))\n",
    "    ndcg = float(np.mean(ndcgs))\n",
    "    prec = float(np.mean(precs))\n",
    "    recall = hr\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0\n",
    "\n",
    "    print(f\"Evaluated users: {len(hits)}, skipped={skipped}\")\n",
    "    print(f\"HR@{topk}: {hr:.4f}\")\n",
    "    print(f\"NDCG@{topk}: {ndcg:.4f}\")\n",
    "    print(f\"Prec@{topk}: {prec:.4f}\")\n",
    "    print(f\"F1@{topk}: {f1:.4f}\")\n",
    "\n",
    "    return {\"HR\": hr, \"NDCG\": ndcg, \"Precision\": prec, \"F1\": f1}"
   ],
   "id": "74e668a02ae6d173",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T02:15:17.584410Z",
     "start_time": "2025-11-18T02:14:57.498994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"===== Validation =====\")\n",
    "val_metrics = eval_split(model, cand_val, val_tgt, topk=10)\n",
    "\n",
    "print(\"\\n===== Test =====\")\n",
    "test_metrics = eval_split(model, cand_test, test_tgt, topk=10)\n",
    "\n",
    "print(\"\\nDone.\")"
   ],
   "id": "7b9b49f1093f0b86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Validation =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval users: 100%|██████████| 64301/64301 [00:10<00:00, 6188.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated users: 39990, skipped=24311\n",
      "HR@10: 0.0240\n",
      "NDCG@10: 0.0096\n",
      "Prec@10: 0.0024\n",
      "F1@10: 0.0044\n",
      "\n",
      "===== Test =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval users: 100%|██████████| 63492/63492 [00:09<00:00, 6583.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated users: 37464, skipped=26028\n",
      "HR@10: 0.0078\n",
      "NDCG@10: 0.0033\n",
      "Prec@10: 0.0008\n",
      "F1@10: 0.0014\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
